{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6428ea45-b490-4c5c-a144-be5abe4f792a",
   "metadata": {},
   "source": [
    "# TF-IDF with spaCy\n",
    "\n",
    "Date: 2024/05/03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6a2304d-c026-4f89-a843-1e16698e6d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatGPTへ「適当な文章をつくってください」の応答\n",
    "\n",
    "text1 = '夕方に勉強していたら、遠くで犬が吠えているのが聞こえた。たぶん、散歩中の他の犬を怖がっているのだろう。'\n",
    "text2 = '毎日、通勤時間に勉強する。勉強は自己への投資。'\n",
    "text3 = '勉強しない上司は嫌い。'\n",
    "text4 = '駅まで歩いている途中、散歩中の犬が私に向かって吠えた。'\n",
    "texts = [text1, text2, text3, text4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c751a91-7375-4eab-b39a-ce7faa816c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load('ja_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "26b0fa0a-de40-4664-9cdc-687a889e0d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [[{\"TEXT\": \"勉強\"}],[{\"TEXT\": \"犬\"}]]\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"日常\", patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e71f0af0-c762-4638-8764-b0c679c10c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[len 36] 夕方 に 勉強 し て い たら 、 遠く で 犬 が 吠え て いる の が 聞こえ た 。 たぶん 、 散歩 中 の 他 の 犬 を 怖 がっ て いる の だろう 。 \n",
      "[len 15] 毎日 、 通勤 時間 に 勉強 する 。 勉強 は 自己 へ の 投資 。 \n",
      "[len 7] 勉強 し ない 上司 は 嫌い 。 \n",
      "[len 19] 駅 まで 歩い て いる 途中 、 散歩 中 の 犬 が 私 に 向かっ て 吠え た 。 \n"
     ]
    }
   ],
   "source": [
    "for doc in nlp.pipe(texts):\n",
    "    print(f'[len {len(doc)}]', end=' ')\n",
    "    for token in doc:\n",
    "        print(token.text, end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e2e4f2-f754-49d4-b5bb-1e8917b3b8fb",
   "metadata": {},
   "source": [
    "## TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2dd8b6d6-f97e-4764-9936-aded7979c16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[len 36] [len 15] [len 7] [len 19] "
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'勉強': 0.027777777777777776, '犬': 0.05555555555555555},\n",
       " {'勉強': 0.13333333333333333, '犬': 0.0},\n",
       " {'勉強': 0.14285714285714285, '犬': 0.0},\n",
       " {'勉強': 0.0, '犬': 0.05263157894736842}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tf = []\n",
    "\n",
    "for doc in nlp.pipe(texts):\n",
    "    cnt = {'勉強': 0, '犬': 0}\n",
    "    print(f'[len {len(doc)}]', end=' ')\n",
    "    matches = matcher(doc, as_spans=True)\n",
    "    #print(len(matches))\n",
    "    for span in matches:\n",
    "        #print(span.text, span.label_)\n",
    "        cnt[span.text] += 1\n",
    "    tf = {}\n",
    "    for k,v in cnt.items():\n",
    "        tf[k] = v/len(doc)\n",
    "    all_tf.append(tf)\n",
    "\n",
    "all_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf0bf59-10b5-4c76-9d6a-524f4b5172f5",
   "metadata": {},
   "source": [
    "## IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6b6d62eb-97ee-4534-bd75-5b9586aaeca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'勉強': 3, '犬': 2}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_cnt = {}\n",
    "for tf in all_tf:\n",
    "    for k,v in tf.items():\n",
    "        if k not in sent_cnt:\n",
    "            sent_cnt[k] = 0\n",
    "        if v > 0:\n",
    "            sent_cnt[k] += 1\n",
    "\n",
    "sent_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b396c6ca-bd5e-412d-accb-c1fec541133a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'勉強': 0.28768207245178085, '犬': 0.6931471805599453}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "all_idf = {}\n",
    "           \n",
    "for k,v in sent_cnt.items():\n",
    "    all_idf[k] = math.log(len(texts)/v)\n",
    "\n",
    "all_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db33398-4c8c-42e2-9620-d4b836c59467",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9372f3d7-5953-4ef2-a9ea-1942afcb1b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'勉強': 0.007991168679216135, '犬': 0.03850817669777474},\n",
       " {'勉強': 0.03835760966023745, '犬': 0.0},\n",
       " {'勉強': 0.04109743892168297, '犬': 0.0},\n",
       " {'勉強': 0.0, '犬': 0.03648143055578659}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tf_idf = []\n",
    "\n",
    "for tf in all_tf:\n",
    "    tf_idf = {}\n",
    "    for k,v in tf.items():\n",
    "        tf_idf[k] = v * all_idf[k]\n",
    "    all_tf_idf.append(tf_idf)\n",
    "\n",
    "all_tf_idf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
